import streamlit as st
import pandas as pd
import geopandas as gpd
import folium
import os
import zipfile
from folium.plugins import FloatImage
from streamlit_folium import st_folium
import matplotlib.pyplot as plt
import seaborn as sns

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ ---
st.set_page_config(layout="wide")
st.title("ğŸŒŠ Texas Coastal Hydrologic Monitoring Dashboard")

# --- Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ---
csv_zip = "columns_kept.zip"
shp_zip = "filtered_11_counties.zip"
csv_folder = "extracted_csvs"
shp_folder = "shapefile"

# --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ZIP ---
def extract_nested_csvs(zip_path, extract_to):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    for root, dirs, files in os.walk(extract_to):
        for dir in dirs:
            sub_path = os.path.join(root, dir)
            csvs = [f for f in os.listdir(sub_path) if f.endswith(".csv")]
            if csvs:
                return sub_path
    return extract_to

def extract_shapefile(zip_path, extract_to):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)

csv_path = extract_nested_csvs(csv_zip, csv_folder)
extract_shapefile(shp_zip, shp_folder)

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ---
csv_files = [f for f in os.listdir(csv_path) if f.endswith(".csv")]
all_data = []
for file in csv_files:
    df = pd.read_csv(os.path.join(csv_path, file), low_memory=False)
    if {"ActivityLocation/LatitudeMeasure", "ActivityLocation/LongitudeMeasure", "ActivityStartDate", "CharacteristicName", "ResultMeasureValue"}.issubset(df.columns):
        df = df.dropna(subset=["ActivityLocation/LatitudeMeasure", "ActivityLocation/LongitudeMeasure", "ActivityStartDate", "CharacteristicName", "ResultMeasureValue"])
        df["ActivityStartDate"] = pd.to_datetime(df["ActivityStartDate"], errors="coerce")
        df["ResultMeasureValue"] = pd.to_numeric(df["ResultMeasureValue"], errors="coerce")
        all_data.append(df)

if not all_data:
    st.error("âŒ No valid CSV data found.")
    st.stop()

combined_df = pd.concat(all_data, ignore_index=True)

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ shapefile ---
shapefile_path = None
for file in os.listdir(shp_folder):
    if file.endswith(".shp"):
        shapefile_path = os.path.join(shp_folder, file)
        break
gdf = gpd.read_file(shapefile_path).to_crs(epsg=4326)

# --- Ø§Ù†ØªØ®Ø§Ø¨ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù†Ù‚Ø´Ù‡ ---
param_map = st.selectbox("ğŸ§ª Select Parameter for Map Display", combined_df["CharacteristicName"].unique())

# --- Ø®Ù„Ø§ØµÙ‡ Ø¢Ø®Ø±ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ ---
latest_data = combined_df.sort_values("ActivityStartDate").dropna()
latest_by_station = latest_data.groupby(["ActivityLocation/LatitudeMeasure", "ActivityLocation/LongitudeMeasure", "CharacteristicName"]).tail(1)
map_df = latest_by_station[latest_by_station["CharacteristicName"] == param_map]

# --- Ù†Ù‚Ø´Ù‡ ---
st.subheader("ğŸ—ºï¸ Interactive Map")
m = folium.Map(location=[map_df["ActivityLocation/LatitudeMeasure"].mean(), map_df["ActivityLocation/LongitudeMeasure"].mean()], zoom_start=7)

# Ù†Ù‚Ø´Ù‡ Ú©Ø§Ù†ØªÛŒâ€ŒÙ‡Ø§
folium.GeoJson(
    gdf.__geo_interface__,
    style_function=lambda x: {
        "fillColor": "#0b5394",
        "color": "#0b5394",
        "weight": 2,
        "fillOpacity": 0.2,
    }
).add_to(m)

# Ù†Ù‚Ø§Ø· Ø§ÛŒØ³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§
for _, row in map_df.iterrows():
    folium.CircleMarker(
        location=[row["ActivityLocation/LatitudeMeasure"], row["ActivityLocation/LongitudeMeasure"]],
        radius=min(max(row["ResultMeasureValue"] / 10, 3), 12),
        color="blue",
        fill=True,
        fill_opacity=0.8,
        popup=f"{param_map}: {row['ResultMeasureValue']:.2f}<br>Date: {row['ActivityStartDate'].date()}"
    ).add_to(m)

st_data = st_folium(m, width=1200, height=600)

# --- Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù‚Ø·Ù‡ ---
clicked_coords = st_data.get("last_object_clicked", None)
if clicked_coords:
    lat, lon = round(clicked_coords["lat"], 6), round(clicked_coords["lng"], 6)
    st.markdown(f"ğŸ“ Selected Station: `{lat}, {lon}`")
    if st.button("Run Analysis"):
        station_df = combined_df[
            (combined_df["ActivityLocation/LatitudeMeasure"].round(6) == lat) &
            (combined_df["ActivityLocation/LongitudeMeasure"].round(6) == lon)
        ]
        if station_df.empty:
            st.warning("No data found for this location.")
        else:
            multi_params = st.multiselect("â• Add Parameters to Plot", station_df["CharacteristicName"].unique())
            if multi_params:
                fig, ax = plt.subplots(figsize=(10, 4))
                for param in multi_params:
                    subset = station_df[station_df["CharacteristicName"] == param]
                    ax.plot(subset["ActivityStartDate"], subset["ResultMeasureValue"], label=param)
                ax.legend()
                ax.set_xlabel("Date")
                ax.set_ylabel("Value")
                ax.set_title("Time Series")
                ax.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b-%Y'))
                fig.autofmt_xdate()
                st.pyplot(fig)

                # Correlation heatmap
                pivot_df = station_df[station_df["CharacteristicName"].isin(multi_params)]
                pivot_wide = pivot_df.pivot_table(index="ActivityStartDate", columns="CharacteristicName", values="ResultMeasureValue")
                corr = pivot_wide.corr()
                st.subheader("ğŸ”— Parameter Correlation Heatmap")
                fig2, ax2 = plt.subplots()
                sns.heatmap(corr, annot=True, cmap="coolwarm", ax=ax2)
                st.pyplot(fig2)
